{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb03601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved under ID: d800b2f5-e79b-40a1-a2fa-d3df0e678ce0\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    all_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                all_text += text + \"\\n\"\n",
    "    return all_text\n",
    "\n",
    "def generate_unique_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def save_to_db(unique_id, resume_text=None, questions=None, db_path='db.json'):\n",
    "    # Load existing db.json file or create new one\n",
    "    if os.path.exists(db_path):\n",
    "        with open(db_path, 'r') as f:\n",
    "            try:\n",
    "                db = json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                db = {}\n",
    "    else:\n",
    "        db = {}\n",
    "\n",
    "    # Create new entry if not exists\n",
    "    if unique_id not in db:\n",
    "        db[unique_id] = {\n",
    "            \"resume\": resume_text or \"\",\n",
    "            \"questions\": [],\n",
    "            \"solutions\": [],\n",
    "            \"question_index\": 0,\n",
    "            \"subquestion_index\": -1,\n",
    "            \"current_answer\":[],\n",
    "            \"answers\":[],\n",
    "            \"question_asked\": \"\"\n",
    "\n",
    "        }\n",
    "\n",
    "    # Update fields if provided\n",
    "    if resume_text:\n",
    "        db[unique_id][\"resume\"] = resume_text\n",
    "    if questions:\n",
    "        db[unique_id][\"questions\"] = [q.model_dump() for q in questions]\n",
    "\n",
    "    # Save DB back\n",
    "    with open(db_path, 'w') as f:\n",
    "        json.dump(db, f, indent=4)\n",
    "        \n",
    "pdf_file = \"resume2.pdf\"\n",
    "resume_text = extract_data_from_pdf(pdf_file)\n",
    "unique_id = generate_unique_id()\n",
    "save_to_db(unique_id, resume_text)\n",
    "\n",
    "print(f\"Data saved under ID: {unique_id}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d691d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"GOOGLE_API_KEY\"]=\"AIzaSyDJQ9e80Hw-oZdCx1cUDIX0giAR1vGFqXA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19be69cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Interview Questions from Sample Resume ---\n",
      "Sending request to Gemini model (gemini-1.5-flash-latest)...\n",
      "\n",
      "--- Successfully Generated Interview Questions ---\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class InterviewQuestion(BaseModel):\n",
    "    question: str = Field(..., description=\"The main interview question.\")\n",
    "    subquestions: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"A list of 1-2 subquestions related to the main question.\"\n",
    "    )\n",
    "\n",
    "class InterviewQuestionsList(BaseModel):\n",
    "    questions: List[InterviewQuestion] = Field(\n",
    "        ...,\n",
    "        description=\"A list containing exactly 5 interview questions (1 intro, 4 technical).\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY environment variable not set.\")\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please set the GOOGLE_API_KEY environment variable before running the script.\")\n",
    "\n",
    "\n",
    "def generate_questions_from_resume(\n",
    "    resume_text: str,\n",
    "    model_name: str = \"gemini-1.5-flash-latest\" # Or \"gemini-1.5-pro-latest\" for potentially higher quality\n",
    ") -> Optional[List[InterviewQuestion]]:\n",
    "    \"\"\"\n",
    "    Generates technical interview questions from resume text using a Gemini model.\n",
    "\n",
    "    Args:\n",
    "        resume_text: The full text of the candidate's resume.\n",
    "        model_name: The Gemini model to use.\n",
    "\n",
    "    Returns:\n",
    "        A list of InterviewQuestion objects if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"API key not configured. Cannot proceed.\")\n",
    "        return None\n",
    "    generation_config = genai.types.GenerationConfig(\n",
    "        response_mime_type=\"application/json\"\n",
    "    )\n",
    "    model = genai.GenerativeModel(model_name, generation_config=generation_config)\n",
    "\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert Technical interviewer. Your task is to analyze the provided resume text and generate exactly 6 interview questions:\n",
    "    1.  One introductory question: This should be a general question to start the interview and allow the candidate to introduce themselves or their resume.\n",
    "    2.  Next Five technical questions: These questions MUST be directly derived from the skills, experiences, projects, or technologies mentioned in the resume. They should probe the candidate's understanding and practical experience and these questions should be on medium level little tricky and little easy.\n",
    "\n",
    "    For EACH of the 6 questions, you MUST also provide 1 or 2 relevant subquestions to dig deeper into the candidate's response.\n",
    "    \n",
    "    The output MUST be a valid JSON object that strictly adheres to the following structure:\n",
    "    A main JSON object with a single key \"questions\".\n",
    "    The value of \"questions\" should be an array of 6 objects.\n",
    "    Each object in the array must have:\n",
    "        - A \"question\" key with a string value (the main question).\n",
    "        - A \"subquestions\" key with an array of 1 or 2 string values (the subquestions).\n",
    "\n",
    "    Example of the exact JSON structure required:\n",
    "    {{\n",
    "      \"questions\": [\n",
    "        {{\n",
    "          \"question\": \"Can you briefly walk me through your resume and highlight your key experiences?\",\n",
    "          \"subquestions\": [\n",
    "            \"What are you most proud of in your career so far?\",\n",
    "            \"What are your career aspirations for the next 5 years?\"\n",
    "          ]\n",
    "        }},\n",
    "        {{\n",
    "          \"question\": \"Your resume mentions experience with Python. Can you describe a challenging project where you extensively used Python?\",\n",
    "          \"subquestions\": [\n",
    "            \"What specific Python libraries or frameworks did you find most useful in that project and why?\",\n",
    "            \"How do you typically handle error management and debugging in your Python applications?\"\n",
    "          ]\n",
    "        }},\n",
    "        // ... (4 more technical questions with subquestions)\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    Do NOT include any text, explanations, or markdown formatting before or after the JSON object.\n",
    "    The entire response should be ONLY the JSON object described.\n",
    "\n",
    "    Resume Text:\n",
    "    ---\n",
    "    {resume_text}\n",
    "    ---\n",
    "\n",
    "    Now, generate the questions based on the resume above in the specified JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Sending request to Gemini model ({model_name})...\")\n",
    "        response = model.generate_content(prompt)\n",
    "        response_json_text = response.text\n",
    "\n",
    "        parsed_output = InterviewQuestionsList.model_validate_json(response_json_text)\n",
    "        \n",
    "        if len(parsed_output.questions) != 6:\n",
    "            print(f\"Warning: Gemini returned {len(parsed_output.questions)} questions instead of 6. Please check the prompt or model behavior.\")\n",
    "\n",
    "        return parsed_output.questions\n",
    "\n",
    "    except genai.types.generation_types.BlockedPromptException as e:\n",
    "        print(f\"Error: The prompt was blocked. {e}\")\n",
    "        return None\n",
    "    except genai.types.generation_types.StopCandidateException as e:\n",
    "        print(f\"Error: Generation stopped unexpectedly. {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Failed to decode JSON response from Gemini: {e}\")\n",
    "        print(f\"Problematic Gemini Response Text:\\n{response_json_text}\")\n",
    "        return None\n",
    "    except ValidationError as e:\n",
    "        print(f\"Error: Gemini response did not match the expected Pydantic model structure: {e}\")\n",
    "        print(f\"Problematic Gemini Response Text (that caused validation error):\\n{response_json_text}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"Script cannot run without GOOGLE_API_KEY. Exiting.\")\n",
    "    else:\n",
    "        \n",
    "        print(\"--- Generating Interview Questions from Sample Resume ---\")\n",
    "        generated_questions = generate_questions_from_resume(resume_text)\n",
    "\n",
    "        if generated_questions:\n",
    "            print(\"\\n--- Successfully Generated Interview Questions ---\")\n",
    "            \n",
    "            save_to_db(\"78afdfab-4395-4c4f-9262-92b041508082\", questions=generated_questions)\n",
    "\n",
    "            # print(json.dumps(generated_questions, indent=2))\n",
    "\n",
    "        else:\n",
    "            print(\"\\n--- Failed to Generate Interview Questions ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c0515",
   "metadata": {},
   "source": [
    "In everyflow we have to check if the interview is satisfactory till now and to check if the provided id esists or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f438da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Question: Can you briefly walk me through your resume, highlighting the projects and experiences you are most proud of?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_next_question(data, user_id):\n",
    "    user_data = data[user_id]\n",
    "    question_index = user_data[\"question_index\"]\n",
    "    subquestion_index = user_data[\"subquestion_index\"]\n",
    "    questions = user_data[\"questions\"]\n",
    "    if not questions or question_index >= len(questions):\n",
    "        return \"All questions have been asked.\", data\n",
    "\n",
    "    current_question = questions[question_index]\n",
    "    subquestions = current_question.get(\"subquestions\", [])\n",
    "\n",
    "    if subquestion_index == -1:\n",
    "        next_question = current_question[\"question\"]\n",
    "        if subquestions:\n",
    "            user_data[\"subquestion_index\"] = 0\n",
    "        else:\n",
    "            user_data[\"question_index\"] += 1\n",
    "            user_data[\"subquestion_index\"] = -1\n",
    "    elif subquestion_index < len(subquestions):\n",
    "\n",
    "        next_question = subquestions[subquestion_index]\n",
    "        user_data[\"subquestion_index\"] += 1\n",
    "\n",
    "        if user_data[\"subquestion_index\"] >= len(subquestions):\n",
    "            user_data[\"question_index\"] += 1\n",
    "            user_data[\"subquestion_index\"] = -1\n",
    "    else:\n",
    "        user_data[\"question_index\"] += 1\n",
    "        user_data[\"subquestion_index\"] = -1\n",
    "        return get_next_question(data, user_id)\n",
    "    user_data['question_asked']=next_question #to check what is the current question asked\n",
    "    return next_question, data\n",
    "\n",
    "with open(\"db.json\", \"r\") as file:\n",
    "    db = json.load(file)\n",
    "\n",
    "user_id = \"78afdfab-4395-4c4f-9262-92b041508082\"\n",
    "question, updated_data = get_next_question(db, user_id)\n",
    "print(\"Next Question:\", question)\n",
    "\n",
    "# Save back the updated state\n",
    "with open(\"db.json\", \"w\") as file:\n",
    "    json.dump(updated_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "067fd447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Evaluation:\n",
      " That's a good overview of your experience. You've clearly articulated your key projects and highlighted relevant skills.  I appreciate you mentioning the technologies used (React, Node.js, NLP, Machine Learning) in each project, which gives me a better understanding of your technical capabilities.  However, it might be beneficial in future interviews to briefly mention quantifiable results for each project. For example, did AllOne have a specific number of users or did Doctorg's prediction accuracy improve by a certain percentage?  Adding these details would strengthen your answer and demonstrate the impact of your work.\n",
      "\n",
      "Result: Adequate\n",
      "\n",
      "Updated satisfactory_till_now to True and saved user's answer.\n"
     ]
    }
   ],
   "source": [
    "# this will evaluate the answers and will generate an answer and a satisfaction bool\n",
    "import json\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "def evaluate_answer(question: str, resume: str, user_answer: str, model_name=\"gemini-1.5-flash-latest\") -> bool:\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI Technical Interview Evaluator. The question below was generated by you earlier based on the user's resume check is it relevant.\n",
    "\n",
    "    Resume:\n",
    "    ---\n",
    "    {resume}\n",
    "    ---\n",
    "\n",
    "    Question:\n",
    "    \"{question}\"\n",
    "\n",
    "    Candidate's Answer:\n",
    "    \"{user_answer}\"\n",
    "\n",
    "    Now, evaluate the candidate's answer. Be respectful and respond like a normal interviewer giving feedback. \n",
    "    Your evaluation should conclude with either \"Adequate\" or \"Inadequate\".\n",
    "\n",
    "    Only respond with a natural comment and end your response with:\n",
    "    Result: Adequate\n",
    "    OR\n",
    "    Result: Inadequate\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        generation_config = genai.types.GenerationConfig(response_mime_type=\"text/plain\")\n",
    "        model = genai.GenerativeModel(model_name, generation_config=generation_config)\n",
    "        response = model.generate_content(prompt)\n",
    "        print(\"AI Evaluation:\\n\", response.text)\n",
    "\n",
    "        if \"Result: Adequate\" in response.text:\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during AI evaluation: {e}\")\n",
    "        return False\n",
    "\n",
    "def update_user_response(json_path: str, user_id: str, user_answer: str):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    user_data = data.get(user_id)\n",
    "    if not user_data:\n",
    "        print(f\"No data found for user_id: {user_id}\")\n",
    "        return\n",
    "\n",
    "    question = user_data['question_asked']\n",
    "    resume = user_data['resume']\n",
    "    is_satisfactory = evaluate_answer(question, resume, user_answer)\n",
    "    user_data[\"satisfactory_till_now\"] = is_satisfactory\n",
    "    user_data['answers'].append(user_answer)\n",
    "\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"Updated satisfactory_till_now to {is_satisfactory} and saved user's answer.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_id = \"78afdfab-4395-4c4f-9262-92b041508082\"\n",
    "    json_path = \"db.json\"  # Replace with your actual path\n",
    "    user_answer = input(\"Enter candidate's answer: \")\n",
    "\n",
    "    update_user_response(json_path, user_id, user_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142953d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
